# Kernel Flow

![[Pasted image 20240829104416.png]]
### Explained
###### Configuration (Front-end)
- Defined through the front-end.
- Build into an XML file as part of the run package.
###### Global Main (Infrastructure)
- Read configuration data for each product. 
###### Product (Infrastructure)
- ???
###### Algorithm (Calculations)
- `Calculations` part of the code base
- The above design further clarified the specifically grouped calculations and some of which were generalised so could be used in both (e.g. Fund Growth and Roll Calendar).
- Further efforts were made to refactor the calculations and the groupings were extended:
	- Fund
	- Charge
	- Benefits
	- Decrements
	- Claim Cost
	- General
###### Calculation (Calculations)
- `Calculations` part of the code base
### Questions
###### What are Withdrawal Parameters
- [ChatGPT Source](https://chatgpt.com/c/44e83144-ebff-41aa-956e-6bc79a725115)
###### Explain the groupings in the Algorithm section
- Calculations are grouped in that way because multiple products often use the same calculation.

# Kernel Data Structures

![[Pasted image 20240829104827.png]]
### Questions
###### What is Model Point Info
- [[! Terminology#Model Point|Model Point]]
###### How is Shared Memory actually shared ?
- See the *How exactly are the individual chunks placed onto the processors ?* section below.

# Calculation Engine

![[Pasted image 20240829111818.png]]
### Explained

### Questions
##### What is held in the Policy Input Buffer ?
- [[! Terminology#Model Point|Model Point]] data
##### What are Shocks ?
- [[! Terminology#Shocks|Shocks]] data
##### What are Pre-Temporal, Temporal and Post temporal calculations ?
[ChatGPT source](https://chatgpt.com/c/ec3705de-2765-4525-ae48-5c008ebbcd12)
- Pre-temporal
	- Adjustments made prior to main temporal execution to ensure accurate and consistent data.
	- Handling errors, filling in missing data
	- Adjustments to account for risk
	- Aggregating certain elements to simplify temporal elements
- Temporal
	- The cashflow projection
- Post-temporal
	- Summarizing, refining, or interpreting the results generated by the temporal model to provide actionable insights or to meet specific reporting or regulatory requirements.
##### What are Pre-sim and Post-sim calculations and how do they differ from Pre-sim and post-sim temporal ?
- Both generally do the same thing but:
	- Pre-sim and post-sim work on *all data*
	- Pre-temporal and post-temporal work on only the data for a single CPU
		- This is important because each calculation of a chunk performed on a CPU may require pre and post processing (aggregation, etc). 
##### Input Buffer vs Run Buffer ?
- Input Buffer
	- Initial values based on KernelConfig.xml and default values
	- Do not change during execution
- Run Buffer
	- Based on Input Buffer values
	- Do change during execution
##### Explain each available option for splitting into chunks ?
- Policy Split
	- Split based on number of policies
		- 25,000 policies / number of processors
- Sim Split
	- Split based on number of Sims
		- 2000 sims / number of processors
##### Explain the Split process further ?
- Each of the run buffers that make up a chunk altogether contain the simulations, policy information, etc that the chunk needs to run it's calculations.
- For example, the Policy run buffer will contain only the policies that the chunk needs and nothing else. Likewise with 
- *It's not the run buffers themselves that are large, it's what they generate and the processing needed to generate it that require scaling.*
##### Policy vs Sim vs PolicySim ?
- Policy
	- Properties and their values from the model point file that are not dependent on sims or timesteps or anything like that
- Sim
	- Aggregated values based on sim
	- Values that are generated during the run
- Policy Sim
	- Properties and their values from the model point file that do depend on Sim
##### How exactly are the individual chunks placed onto the processors ?
[ChatGPT Source](https://chatgpt.com/c/fa539399-69de-4319-9851-69bc870d905a)
- `multiprocessing` library
- Each processor has it's own python interpreter
	- ME: Remember having to kill the processes in TaskManager
- Important classes/methods that are used
	- `Process`
		- Creates a process to be executed on a CPU, assigning a function to execute (via the `target` parameter) and any arguments the function takes (`config` object)
	- `start`
		- Begin executing the process on a separate processor
- Create a `Process` instance for each processor we wish to utilize
- Iterate through the `Process` instances and execute `start` method
##### How where the results accessed after multiprocessing was complete ?
- Each result was put into it's own local folder that was uniquely identifiable.
##### Where is the individual product info stored ?
- Key:Value property inside the Config object.
- Key is the product name
##### How exactly did one simulation differ from the other ?
- Values related to uncertainty or variability are changed which include
	- Mortality Rates
	- Interest Rates
	- Lapse Rates
	- Inflation
- The actuaries would code in their part of the project how these simulations varied
	- The functions can randomly select values for these values based on their respective probability distributions. 
	- One simulation might assume a high claim frequency and low-interest rates, while another might assume the opposite.
- ME: If you don't know, just say the randomisation was defined in their part of the code.
##### How functions where called dynamically ?
- Dictionary of function pointers instead of `if` statements to make the associated calculation selection.
- Using multiple if conditions can be expensive to perform
	- Also brittle to change

# Database
### What Database Connection library was used ?
- pyodbc

### How was data written to database ?
- The numerical values (including the projection months) of the result  where written in hexadecimal format
- This was stored in one column of the dbo.Results table
- Some of other columns of the same row where 
	- RunTypeName
	- SubRunName
	- VariableName

### How where the values converted to hexadecimal ?
- After files where merged and the data was being written to the database
- The `panda.to_csv` function was used to temporarily write down the results to be written in this iteration (remember the data is written to the database in chunks) before then being written out to the database in that format
- `.map` function was used with a string format like so (`#010x`)
	- `df['col3'] = df['col3'].map('{:#010x}'.format)`

### What credentials where used when connecting to database read and write to ?
- ArcSimWorker

### Was all the data written to the database in one go ?
- No the data was written in smaller parts.
- This was to avoid bandwidth limitations

### How large was a typical run of data ?
- The numerical values (including the projection months) of the result 
- Uncompressed result was 1 GB
- Compressed result was 200-300 MB

# Multiprocessing
### What python library was used  for parallelism ?
- `multiprocessing`

### How where the assumptions passed to each processor ?
- The assumptions and other run information are referenced inside the Config object and almost all functions in the CalculationKernel take the config object as it's first argument
- The config object was created using the `shared` function of the `Manager` class.

### Where did each processor write it's output data during execution ?
- To CSV files in a local folder in the run package as temporary files.
- This folder was unique to the processor it ran on.

### How was the data outputted from each processor merged before being written to the database ?
- Each CSV file written out would contain unique information about that run.
- These files can then be merged into a single file for further processing without any overwriting occurring.
- Some aggregation and ordering did occur

### How was the input information represented in python ?
- Using python objects
- Used the dynamic aspect of python to dynamically assign properties and method calls to objects
- Accessed those properties using dictionary syntax.

### How was results written to CSV in each processor ?
- Results where maintained in a panda dataframe.
- Used a function in panda called `to_csv()`.

### How was the workload split ?
- Policy-Split
	- 20,000 policies for AI (250,000 policies for ALV)
		- 20,000 divided by number of processes
	- Each processor would get a policy range.
- Sim-split
	- E.g. 2000 sim run divided by the number of processors
	- Each processor would run a certain range of simulations

### How was synchronization managed ?
- Each processor had its own copy of the data

# Project structure
- **Infrastructure**
	- Managed by Dev team
	- Run configuration setup
	- Input Buffers and Run Buffers setup
	- Multithreading
- **Calculations**
	- Managed by actuaries
	- Actuarial calculations

# Performance
### How did ARCSim compare to ModelRP ?
- ModelRp took weekend to run.
- ARCSim took 7-8 hours.

### Explain the performance increase ?
- Nested Loops vs Vectorization approaches shown below for a single thread.
- Notice also how well it scales based on the number of sims
![[Pasted image 20240829175554.png|500]]

### What core functionality made the CalculationEngine so fast was ?
##### Matrix Multiplication and Vectorization 
- Initial implementations had 3 nested loops
	- PolicyLoop (loop through all policies of a product)
		- Simulation Loop (loop through all simulations required)
			- Temporal (loop through monthly timesteps of the product)
- Refactor removed the nested loops and instead grouped by policies and simulations into a vector. This vector then performs multiple sim calculations at the same time. 
- Explained further in this [ChatGPT answer](https://chatgpt.com/c/71e8124f-b3fc-4a28-af81-36bea1576656) (check highlights)
##### Single Instruction Multiple Data
- Vectorization solution can use SIMD (Single Instruction, Multiple Data) and can provide some substantial speed gains
	- [Video](https://www.youtube.com/watch?v=ulmjqD6Y4do) on SIMD
- ChatGPT answer [here](https://chatgpt.com/c/f120a18d-3fb9-4286-9de2-e9a0ee538e8b)

### How was performance measured ?
- Proof of Concepts
- Implemented one product at the start comparing the runtimes produced with current software (ModelRp, Prophet).
- Used Single thread at the start
- By showing how product A was much faster, we used Excel formulas to extrapolate this to other products to show how they would also speed up if implemented.
	- This extrapolation was done based on the *number of policies* for that product.

### Apart from faster execution time, what else was improved ?
- Auditable
- Code clarity
- Extensibility

### What other improvements outside of speed was done ?
##### Runs Grouped by SubRun/SimRange instead of Product
- Hit a ceiling with speed increase
- However, there was an external issue with incorrect assumption or input information.
- The Reporting team would not find this out until runs are complete
- Decision to switch from per-product runs to pr SubRunName runs and SimRange.
- All product info is passed into one run.
- Users could tell after initial few runs if results are looking okay and proceed with the remaining runs.
- The runs didn't finish faster but the overall reporting period at a quarter end was much shorter due to less re-runs.
##### Model Point Info
- We had full control over how the policies where grouped for the Model Point stage

### Weaknesses of New Implementation
- Still could be faster
	- Proposal to use **Rust** to rewrite multi-threading aspect.

# Hosting
- Hosted source code on same server as GUI and Console
- When Projection run occurred, Console packages source code along with:
	- XML file detailing the run configuration such as Input data, steps, etc
	- Batch file which contained the command that would execute the process starting at Main.py file.
- This was then called a run package that was labelled with the RunId of the run and sent to an available AWS server for execution.

# Run Configurations
### Aegon Ireland
- 25 products 
- 720 months/timesteps and 2000 simulations per product.

# Excel, XML, CSV
### How was XML file read in ?
- `xml.etree.ElementTree`
```python
import xml.etree.ElementTree as ET
tree = ET.parse('Config.xml')
root = tree.getroot()
print(root.findall('.//Log'))
```

### What library was used to output Excel ?
- `XlWings` (need to install excel add-in)

### What was the format of the CSV files ?
- Y-axis: Output Variables
- X-axis: Timesteps (but other columns like SunRunName, RunId, etc)
	- Exact same format as dbo.Result table but Timesteps are expanded.